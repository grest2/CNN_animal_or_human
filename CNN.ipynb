{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgCoUtuWwgGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySvGn91kqLdu",
        "colab_type": "code",
        "outputId": "ae942639-0b09-4259-8a2f-b24957583645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive2; to attempt to forcibly remount, call drive.mount(\"/content/drive2\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl8iOXHMrpSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q \"/content/drive2/My Drive/Dataset.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0pUy0r0r6bI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jFK5Y_CsAcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtKakMs6sCJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOveixbcsGrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = os.path.join( 'Dataset')\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir=os.path.join(base_dir,'test')\n",
        "train_animals_dir = os.path.join(train_dir, 'animals')\n",
        "train_humans_dir = os.path.join(train_dir, 'human')\n",
        "validation_animals_dir = os.path.join(validation_dir, 'animals')\n",
        "validation_humans_dir = os.path.join(validation_dir, 'human')\n",
        "tests_animals_dir = os.path.join(test_dir, 'animals')\n",
        "tests_humans_dir = os.path.join(test_dir, 'human')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7j51GAPsk1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_animals_tr = len(os.listdir(train_animals_dir))\n",
        "num_humans_tr=len(os.listdir(train_humans_dir))\n",
        "num_animals_val = len(os.listdir(validation_animals_dir))\n",
        "num_humans_val=len(os.listdir(validation_humans_dir))\n",
        "num_animals_ts = len(os.listdir(tests_animals_dir))\n",
        "num_humans_ts=len(os.listdir(tests_humans_dir))\n",
        "\n",
        "total_train = num_animals_tr+num_humans_tr\n",
        "total_val = num_animals_val+num_humans_val\n",
        "total_test=num_animals_ts+num_humans_ts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8KPnXSotl1Q",
        "colab_type": "code",
        "outputId": "339b216f-a114-43f4-be95-402acb391e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "print('Животных в тестовом наборе данных: ', num_animals_tr)\n",
        "print('Людей в тестовом наборе данных: ', num_humans_tr)\n",
        "print('Животных в валидационном наборе данных: ', num_animals_val)\n",
        "print('Людей в валидационном наборе данных: ', num_humans_val)\n",
        "print('--')\n",
        "print('Всего изображений в тренировочном наборе данных: ', total_train)\n",
        "print('Всего изображений в валидационном наборе данных: ', total_val)\n",
        "print('Всего изображений в тестовом наборе данных: ', total_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Животных в тестовом наборе данных:  1002\n",
            "Людей в тестовом наборе данных:  614\n",
            "Животных в валидационном наборе данных:  502\n",
            "Людей в валидационном наборе данных:  288\n",
            "--\n",
            "Всего изображений в тренировочном наборе данных:  1616\n",
            "Всего изображений в валидационном наборе данных:  790\n",
            "Всего изображений в тестовом наборе данных:  374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-af6Ddt7aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100 # количество тренировочных изображений для обработки перед обновлением параметров модели\n",
        "IMG_SHAPE = 150 # размерность к которой будет преведено входное изображение"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scyPOPBat-6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotImages(images_arr):\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images_arr, axes):\n",
        "    ax.imshow(img)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnGyd6N6uOwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SHAPE, IMG_SHAPE, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkUbexZbuVfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el-RbZACuYqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsMAKX28ubzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qAo7L7Cx1L3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bddt-UV8x2TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxGnkaiVx6tI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32uQWQBGx-Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-E4hoc0xJp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_test=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_data_gen = image_gen_test.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=test_dir,\n",
        "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibPoJqipdssX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 250\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM0zsOlXyLGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvXQ7hQgd5XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZK3iMMKbmUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a9e2b9a1-07f1-4391-a741-27a88eeba7c8"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data_gen, steps=math.ceil(total_test))\n",
        "print(\"Точность на тестовом наборе данных: \", test_accuracy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "374/374 [==============================] - 571s 2s/step - loss: 0.4132 - acc: 0.8369\n",
            "Точность на тестовом наборе данных:  0.83688754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3knGjPmbu8ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_FILE = \"test_file.txt\"\n",
        "open(TEST_FILE,\"w\")\n",
        "probabilities = model.predict_generator(test_data_gen, 374)\n",
        "for index, probability in enumerate(probabilities):\n",
        "    image_path = test_dir + \"/\" +test_generator.filenames[index]\n",
        "    img = mpimg.imread(image_path)\n",
        "    with open(TEST_FILE,\"a\") as fh:\n",
        "        fh.write(str(probability[0]) + \" for: \" + image_path + \"\\n\")\n",
        "    plt.imshow(img)\n",
        "    if probability > 0.5:\n",
        "        plt.title(\"%.2f\" % (probability[0]*100) + \"% human\")\n",
        "    else:\n",
        "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% animal\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}